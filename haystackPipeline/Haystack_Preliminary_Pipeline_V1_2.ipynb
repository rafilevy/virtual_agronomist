{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Haystack_Preliminary_Pipeline_V1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7W6CReNgcoI"
      },
      "source": [
        "## Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dx3DvFcESED"
      },
      "source": [
        "# Check for running GPU\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oawGovRjEkPF"
      },
      "source": [
        "# Run once for initial installs\r\n",
        "! pip install farm-haystack\r\n",
        "! pip install git+https://github.com/deepset-ai/haystack.git\r\n",
        "! pip install urllib3==1.25.4\r\n",
        "! pip install torch==1.6.0+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwGqL8YjCX_r"
      },
      "source": [
        "# Run this if want to see graphic representation of pipeline \r\n",
        "! apt install libgraphviz-dev graphviz\r\n",
        "! pip install pygraphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OINw-zqjFooP"
      },
      "source": [
        "# Start Elasticsearch from source\r\n",
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.2-linux-x86_64.tar.gz -q\r\n",
        "! tar -xzf elasticsearch-7.6.2-linux-x86_64.tar.gz\r\n",
        "! chown -R daemon:daemon elasticsearch-7.6.2\r\n",
        "! sleep 30"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1JXvtG1KFbu",
        "outputId": "b5e1188f-5ace-49b1-ad26-ad6fea8e6069"
      },
      "source": [
        "# Connect to Elasticsearch\r\n",
        "import os\r\n",
        "from subprocess import Popen, PIPE, STDOUT\r\n",
        "es_server = Popen(['elasticsearch-7.6.2/bin/elasticsearch'],\r\n",
        "                   stdout=PIPE, stderr=STDOUT,\r\n",
        "                   preexec_fn=lambda: os.setuid(1)\r\n",
        "                  )\r\n",
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\r\n",
        "document_store = ElasticsearchDocumentStore(similarity=\"dot_product\", host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:53:20 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.127s]\n",
            "02/14/2021 02:53:20 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.014s]\n",
            "02/14/2021 02:53:20 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.071s]\n",
            "02/14/2021 02:53:20 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.018s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb566go43uNz"
      },
      "source": [
        "import pprint\r\n",
        "pp = pprint.PrettyPrinter(indent=2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW60g6FZgjL0"
      },
      "source": [
        "## Document Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT3fxP2UKHcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7be26a9-951b-4cad-f1b9-2b4861019953"
      },
      "source": [
        "from haystack.preprocessor.cleaning import clean_wiki_text\r\n",
        "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\r\n",
        "from haystack.reader.farm import FARMReader\r\n",
        "import haystack\r\n",
        "\r\n",
        "converter = haystack.file_converter.txt.TextConverter(\r\n",
        "                    remove_numeric_tables=False,\r\n",
        "                    valid_languages = [\"en\"])\r\n",
        "\r\n",
        "as4 = converter.convert(file_path=\"/content/as4-winterBarley.txt\")\r\n",
        "\r\n",
        "\r\n",
        "processor = haystack.preprocessor.preprocessor.PreProcessor(\r\n",
        "    clean_empty_lines=True,\r\n",
        "    clean_whitespace=True,\r\n",
        "    clean_header_footer=True,\r\n",
        "    split_by=\"passage\",\r\n",
        "    split_length=1,\r\n",
        "    split_respect_sentence_boundary=False,\r\n",
        "    split_overlap=0\r\n",
        ")\r\n",
        "\r\n",
        "as4Docs = processor.process(as4)\r\n",
        "# print(as4Docs)\r\n",
        "\r\n",
        "# ! docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.6.2\r\n",
        "\r\n",
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\r\n",
        "document_store = ElasticsearchDocumentStore(\r\n",
        "    host=\"localhost\",\r\n",
        "    username=\"\",\r\n",
        "    password=\"\",\r\n",
        "    index=\"document\"\r\n",
        ")\r\n",
        "\r\n",
        "document_store.delete_all_documents(index='document')\r\n",
        "document_store.write_documents(as4Docs)\r\n",
        "\r\n",
        "backagain = document_store.get_all_documents();\r\n",
        "\r\n",
        "for i in range(0,len(as4Docs)):\r\n",
        "    print(str(i) + \":\", end = \" \")\r\n",
        "    print(as4Docs[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:53:27 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.006s]\n",
            "02/14/2021 02:53:27 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.003s]\n",
            "02/14/2021 02:53:27 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.015s]\n",
            "02/14/2021 02:53:27 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.004s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:53:27 - INFO - elasticsearch -   POST http://localhost:9200/document/_delete_by_query [status:200 request:0.209s]\n",
            "02/14/2021 02:53:30 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.978s]\n",
            "02/14/2021 02:53:30 - INFO - elasticsearch -   POST http://localhost:9200/document/_search?scroll=1d&size=10000 [status:200 request:0.023s]\n",
            "02/14/2021 02:53:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.005s]\n",
            "02/14/2021 02:53:30 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.004s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: {'text': 'Three-spray programmes are recommended for winter barley due to its response to T3 fungicides and the rise in severity of late season ramularia. As such T1 and T2 can be applied slightly earlier if required to better match up with PGR timings.', 'meta': {'_split_id': 0}}\n",
            "1: {'text': 'The main fungicide used for winter barley disease control is Prothioconazole; however growers should look to protect this active by including alternative modes of action.', 'meta': {'_split_id': 1}}\n",
            "2: {'text': 'For winter barley, timing for T1 (GS30-31) is important due to more GAI on lower than on upper leaves. The slightly earlier timing will allow better pairing with an early growth regulator and reduce the need for a T0 treatment.', 'meta': {'_split_id': 2}}\n",
            "3: {'text': 'For winter barley, T1 (GS30-31) application options are:\\nSiltra Xpro 0.4 -0.6 l/ha\\nCebara 1.0 -1.5 l/ha + Proline 0.25 l/ha,\\nComet 0.4 l/ha + Proline 0.3-0.4 l/ha\\nFandango 0.75 -1.0 l/ha\\nElatus Era 0.6 -0.8 l/ha\\nCyprodinil (in Cebara) will have useful activity against eyespot and mildew, also net blotch in which resistance to azoles and SDHIs is increasing.', 'meta': {'_split_id': 3}}\n",
            "4: {'text': 'For winter barley, an earlier timing for the T2 (GS37-39) will make inclusion of ethephon-based PGRs easier.', 'meta': {'_split_id': 4}}\n",
            "5: {'text': 'For winter barley, the justification for high doses at T2 (GS37-39) is difficult to prove as cost effective, the inclusion of a third spray further decreases the need for higher doses of product, in NIAB TAG trials; however brown rust susceptibility and early T2 applications may require higher doses.', 'meta': {'_split_id': 5}}\n",
            "6: {'text': 'For winter barley, T2 (GS43-39) application options are:\\nSiltra Xpro 0.4 -0.6 l/ha\\nCebara + Proline 0.75 -1.0 l/ha + 0.33 l/ha\\nComet + Proline 0.3 l/ha + 0.3 -0.4 l/ha\\nFandango 0.75 -1.0 l/ha\\nPriaxor 0.75-1.0 l/ha\\nElatus Era 0.4 -0.6 l/ha\\nIn all cases add chlorothalonil (CTL) 500 g/ha.', 'meta': {'_split_id': 6}}\n",
            "7: {'text': 'For winter barley, only minimal input is needed for T3 (GS49-59) applications (to top up earlier treatments and provide a vehicle for a second CTL application). Application options are:\\nProline 0.25 l/ha\\nBumper 0.25 l/ha\\nFandango 0.5 l/ha (Only two strobilurin applications permitted per crop)\\nPriaxor 0.75 l/ha (Only two strobilurin applications permitted per crop)\\nIn all cases add chlorothalonil (500 g/ha).', 'meta': {'_split_id': 7}}\n",
            "8: {'text': 'The only reliable control option for ramularia in winter barley is chlorothalonil (CTL).', 'meta': {'_split_id': 8}}\n",
            "9: {'text': 'There has been considerable debate as to whether winter barley needs treating for ramularia at T1: it is unlikely to be controllable at this early timing but in a traditional two-spray programme, with the second treatment applied at GS49 (first awns), there is likely to be a benefit to treating earlier than this.', 'meta': {'_split_id': 9}}\n",
            "10: {'text': 'A three-spray programme for winter barley allows chlorothalonil (CTL) to be used with the latter two sprays, (so no requirement at T1) but if employing a two-spray programme (or three-sprays at T0, T1 and T2) then it would be wise to include chlorothalonil (CTL) at T1.', 'meta': {'_split_id': 10}}\n",
            "11: {'text': 'For winter barley, in high disease pressure seasons (mild wet early spring) T0 sprays have been necessary. Although earlier timings in a T1/T2/T3 programme should remove the need for separate T0 treatment.', 'meta': {'_split_id': 11}}\n",
            "12: {'text': 'Although a three-spray programme is suggested for winter barley, a traditional two-spray approach will still give effective disease control but please note: T0 fungicides are more likely to be needed chlorothalonil (CTL) should be included at T1 if the second treatment is not applied until GS49. In all cases add a morpholine to the T0 if mildew is actively developing or if rusts are present requiring rapid knockdown (e.g. Corbel 0.3 l/ha).', 'meta': {'_split_id': 12}}\n",
            "13: {'text': 'T3: 2018 was a very low disease year but still large responses to fungicide use. Responses to T3 treatment have been higher in the north for some time but responses are still high generally.', 'meta': {'_split_id': 13}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrR-AGlxgqob"
      },
      "source": [
        "## Building Individual Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFIjvlTwLSoN"
      },
      "source": [
        "# Naive retriver based on tf * idf - Default BM25, can be cunstomised\r\n",
        "from haystack.retriever.sparse import ElasticsearchRetriever\r\n",
        "es_retriever = ElasticsearchRetriever(document_store=document_store)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFr-plj4B0o"
      },
      "source": [
        "# Alternative retriever - double BERT neural networks for question and doc embedding\r\n",
        "from haystack.retriever.dense import DensePassageRetriever\r\n",
        "dpr_retriever = DensePassageRetriever(document_store=document_store,\r\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\r\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\r\n",
        "                                  max_seq_len_query=64,\r\n",
        "                                  max_seq_len_passage=256,\r\n",
        "                                  batch_size=16,\r\n",
        "                                  use_gpu=True,\r\n",
        "                                  embed_title=True,\r\n",
        "                                  use_fast_tokenizers=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuTEG8eN9UWm",
        "outputId": "92a23275-2663-40a4-f3f8-9ea05cf172be"
      },
      "source": [
        "# Alternative retriever - single BERT to embed both question and doc, may be better for similar documents (our case)\r\n",
        "from haystack.retriever.dense import EmbeddingRetriever\r\n",
        "embedding_retriever = EmbeddingRetriever(document_store=document_store,\r\n",
        "                               embedding_model=\"deepset/sentence_bert\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:54:22 - INFO - haystack.retriever.dense -   Init retriever using embeddings of model deepset/sentence_bert\n",
            "02/14/2021 02:54:22 - INFO - farm.utils -   Using device: CUDA \n",
            "02/14/2021 02:54:22 - INFO - farm.utils -   Number of GPUs: 1\n",
            "02/14/2021 02:54:22 - INFO - farm.utils -   Distributed Training: False\n",
            "02/14/2021 02:54:22 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
            "02/14/2021 02:54:36 - WARNING - farm.utils -   Failed to log params: Changing param values is not allowed. Param with key='prediction_heads' was already logged with value='TextSimilarityHead' for run ID='9fdfbabba2b84909864a6cf672644903'. Attempted logging new value ''.\n",
            "02/14/2021 02:54:38 - WARNING - farm.utils -   Failed to log params: Changing param values is not allowed. Param with key='processor' was already logged with value='TextSimilarityProcessor' for run ID='9fdfbabba2b84909864a6cf672644903'. Attempted logging new value 'InferenceProcessor'.\n",
            "02/14/2021 02:54:38 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Using device: CUDA \n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Number of GPUs: 1\n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Distributed Training: False\n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
            "02/14/2021 02:54:38 - WARNING - haystack.retriever.dense -   You seem to be using a Sentence Transformer with the dot_product function. We recommend using cosine instead. This can be set when initializing the DocumentStore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ursLVOh7-daI"
      },
      "source": [
        "# Customised retriever - add in future filter for special key words?\r\n",
        "from haystack.retriever.dense import BaseRetriever\r\n",
        "class CustomRetriever(BaseRetriever):\r\n",
        "  def retrieve(self,query,filters=None,top_k=10,index=None):\r\n",
        "    super().retrieve(query,filters,top_k,index)\r\n",
        "    #placeholder retriever\r\n",
        "    return []\r\n",
        "\r\n",
        "custom_retriever = CustomRetriever()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sXdUWDpMzsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5126a0c-59a4-4905-eff1-51a80126bd35"
      },
      "source": [
        "# Reader to further scan with Hugging Face models\r\n",
        "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)\r\n",
        "reader = FARMReader(model_name_or_path=\"deepset/bert-large-uncased-whole-word-masking-squad2\", use_gpu=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:54:38 - INFO - farm.utils -   Using device: CUDA \n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Number of GPUs: 1\n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Distributed Training: False\n",
            "02/14/2021 02:54:38 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
            "02/14/2021 02:56:11 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
            "02/14/2021 02:56:11 - INFO - farm.utils -   Using device: CUDA \n",
            "02/14/2021 02:56:11 - INFO - farm.utils -   Number of GPUs: 1\n",
            "02/14/2021 02:56:11 - INFO - farm.utils -   Distributed Training: False\n",
            "02/14/2021 02:56:11 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
            "02/14/2021 02:56:11 - INFO - farm.infer -   Got ya 2 parallel workers to do inference ...\n",
            "02/14/2021 02:56:11 - INFO - farm.infer -    0    0 \n",
            "02/14/2021 02:56:11 - INFO - farm.infer -   /w\\  /w\\\n",
            "02/14/2021 02:56:11 - INFO - farm.infer -   /'\\  / \\\n",
            "02/14/2021 02:56:11 - INFO - farm.infer -     \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVwNkA6TBRp1",
        "outputId": "df778067-f4e4-4c36-9a56-5fb07a7a854b"
      },
      "source": [
        "document_store.update_embeddings(dpr_retriever) #possible training of dpr model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 02:56:11 - INFO - elasticsearch -   POST http://localhost:9200/document/_count [status:200 request:0.074s]\n",
            "02/14/2021 02:56:11 - INFO - haystack.document_store.elasticsearch -   Updating embeddings for all 14 docs ...\n",
            "02/14/2021 02:56:11 - INFO - elasticsearch -   POST http://localhost:9200/document/_search?scroll=1d&size=10000 [status:200 request:0.011s]\n",
            "02/14/2021 02:56:11 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.005s]\n",
            "02/14/2021 02:56:11 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.004s]\n",
            "02/14/2021 02:56:12 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.517s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIkR1zR4DU__"
      },
      "source": [
        "# For winter barley only timing is necessary, to be completed for the full document\r\n",
        "filters_dictionary = { \"timings\":[\"t0\",\"t1\",\"t2\",\"t3\"],\r\n",
        "                       \"fungus\":[\"ramularia\", \"rellow rust\"],\r\n",
        "                       \"areas\":[\"east\", \"north\", \"southeast\", \"west\", \"south\", \"southwest\"]}\r\n",
        "questions = { \"timings\":\"Is there a specific timing that you would like to ask about? (E.g. T0, T1, etc)\",\r\n",
        "              \"fungus\":\"Is there a fungi type that you would want to know about specifically?\",\r\n",
        "              \"area\":\"Which area are you in? (E.g. east, north, etc)\"}\r\n",
        "\r\n",
        "class FurtherQuestionGenerator:\r\n",
        "  outgoing_edges = 1\r\n",
        "\r\n",
        "  def individualFiltersGenerator(self, text):\r\n",
        "    current_filters = {}\r\n",
        "    for category, filters in filters_dictionary.items():\r\n",
        "      for filter in filters:\r\n",
        "        if filter in text.lower():\r\n",
        "          if category in current_filters:\r\n",
        "            current_filters[category].append(filter)\r\n",
        "          else:\r\n",
        "            current_filters[category] = [filter]\r\n",
        "    return current_filters\r\n",
        "\r\n",
        "  def topDocsFilterGenerator(self, docs):\r\n",
        "    return [self.individualFiltersGenerator(doc.text) for doc in docs]\r\n",
        "\r\n",
        "  def filters_difference(self, filters_list, specified = []):\r\n",
        "    current_filters = {}\r\n",
        "    for filters in filters_list:\r\n",
        "      for category, filters in filters.items():\r\n",
        "        if ((category not in specified) and (category in current_filters) and (filters != current_filters[category])):\r\n",
        "          return category\r\n",
        "        elif ((category not in specified) and (category not in current_filters)):\r\n",
        "          current_filters[category] = filters\r\n",
        "    return None\r\n",
        "\r\n",
        "  def furtherQuestions(self, docs,specified = []):\r\n",
        "    filters_list = self.topDocsFilterGenerator(docs)\r\n",
        "    match = [0 for doc in docs]\r\n",
        "    keyword = self.filters_difference(filters_list,specified)\r\n",
        "    while keyword is not None:\r\n",
        "      new_key = input(questions[keyword] + \" \")\r\n",
        "      match = [match[i] + 1 if ((keyword in filters_list[i].keys()) and (new_key.lower() in filters_list[i][keyword])) else match[i] for i in range(len(filters_list))]\r\n",
        "      match = [match[i] + 1 if ((keyword in filters_list[i].keys()) and (filters_list[i][keyword] == [new_key.lower()])) else match[i] for i in range(len(filters_list))]\r\n",
        "      specified.append(keyword)\r\n",
        "      keyword = self.filters_difference(filters_list,specified)\r\n",
        "    return [x for _,x in sorted(zip(match,docs), key=lambda pair: pair[0], reverse=True)]\r\n",
        "\r\n",
        "  def run(self, **kwargs):\r\n",
        "    specified = list(self.individualFiltersGenerator(kwargs[\"query\"]).keys())\r\n",
        "    return (self.furtherQuestions(kwargs[\"documents\"],specified),\"output_1\")\r\n",
        "\r\n",
        "question_generator = FurtherQuestionGenerator()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHatnDA3g2ON"
      },
      "source": [
        "## Assembling into Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwIgVaYeNPoS"
      },
      "source": [
        "#from haystack.pipeline import ExtractiveQAPipeline\r\n",
        "\r\n",
        "# Original Finder deprecated, pipeline allows more flexibility\r\n",
        "# prediction = finder.get_answers(question=\"Who is the father of Arya Stark?\", top_k_retriever=10, top_k_reader=5)\r\n",
        "\r\n",
        "# top_k_retriever -> the more retriever the more document scanned in Reader, slower but higher hit rate\r\n",
        "#extractive_pipeline = ExtractiveQAPipeline(reader=reader, retriever=dpr_retriever) # Other options: Document Search, Generative, FAQ"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1EDRXomPo4X"
      },
      "source": [
        "# Naive approach - can fall back upon this if anything goes wrong\r\n",
        "# question = 'what are the T1 appkication option for winter barley?'\r\n",
        "# prediction = extractive_pipeline.run(query=question, top_k_retriever=2, top_k_reader=2)\r\n",
        "# print_answers(prediction, details=\"all\") #details: all, medium, minimal\r\n",
        "# data format: {query,'answers':[{'answer','score','probability','context','document_id','offset','meta'}]}\r\n",
        "# pp.pprint(prediction['answers'])\r\n",
        "# pp.pprint(dpr_retriever.retrieve(query=question,top_k=13))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL2KPGY8upfv",
        "outputId": "2f570ec0-6d65-4789-e6af-fe1236c9726a"
      },
      "source": [
        "# Current approach\r\n",
        "from haystack import Pipeline\r\n",
        "from haystack.pipeline import JoinDocuments\r\n",
        "\r\n",
        "# Building new pipeline with multiple retrievers\r\n",
        "pipeline = Pipeline()\r\n",
        "pipeline.add_node(component=es_retriever, name=\"ESRetriever\", inputs=[\"Query\"])\r\n",
        "pipeline.add_node(component=dpr_retriever, name=\"DPRRetriever\", inputs=[\"Query\"])\r\n",
        "pipeline.add_node(component=embedding_retriever, name=\"EmbeddingRetriever\", inputs=[\"Query\"])\r\n",
        "pipeline.add_node(component=custom_retriever, name=\"CustomRetriever\", inputs=[\"Query\"])\r\n",
        "pipeline.add_node(component=JoinDocuments(join_mode=\"merge\"), name=\"JoinResults\", inputs=[\"ESRetriever\", \"DPRRetriever\", \"EmbeddingRetriever\", \"CustomRetriever\"])\r\n",
        "pipeline.add_node(component=question_generator, name=\"QnGenerator\", inputs=[\"JoinResults\"])\r\n",
        "# pipeline.draw(path=\"custom_pipe.png\")\r\n",
        "\r\n",
        "# Question input goes here\r\n",
        "question = input(\"What would you like to ask about?\")\r\n",
        "responses = pipeline.run(query=question, top_k_retriever=5)\r\n",
        "\r\n",
        "# Final answer is here \r\n",
        "print(responses[0].text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What would you like to ask about?what should I spray for winter barley?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "02/14/2021 03:02:40 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.009s]\n",
            "02/14/2021 03:02:40 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.011s]\n",
            "02/14/2021 03:02:40 - WARNING - farm.data_handler.processor -   Currently no support in InferenceProcessor for returning problematic ids\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.40 Batches/s]\n",
            "02/14/2021 03:02:40 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.012s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Is there a specific timing that you would like to ask about? (E.g. T0, T1, etc) T0\n",
            "A three-spray programme for winter barley allows chlorothalonil (CTL) to be used with the latter two sprays, (so no requirement at T1) but if employing a two-spray programme (or three-sprays at T0, T1 and T2) then it would be wise to include chlorothalonil (CTL) at T1.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}